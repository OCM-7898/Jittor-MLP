{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import jittor as jt\n",
    "from models_jittor import gMLPForImageClassification as gMLP_jt\n",
    "from models_jittor import ResMLPForImageClassification as ResMLP_jt\n",
    "from models_jittor import MLPMixerForImageClassification as MLPMixer_jt\n",
    "from models_jittor import ViP as ViP_jt\n",
    "from models_jittor import S2MLPv2 as S2MLPv2_jt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "from models_pytorch import gMLPForImageClassification as gMLP_pt\n",
    "from models_pytorch import ResMLPForImageClassification as ResMLP_pt\n",
    "from models_pytorch import MLPMixerForImageClassification as MLPMixer_pt\n",
    "from models_pytorch import ViP as ViP_pt\n",
    "from models_pytorch import S2MLPv2 as S2MLPv2_pt \n",
    "import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model_jt = gMLP_jt(\n",
    "#     image_size=224,\n",
    "#     patch_size=16,\n",
    "#     in_channels=3,\n",
    "#     num_classes=1000,\n",
    "#     d_model=256,\n",
    "#     d_ffn=1536,\n",
    "#     depth=30,\n",
    "# )\n",
    "\n",
    "# model_jt = ResMLP_jt(\n",
    "#     in_channels = 3,\n",
    "#     image_size = 224,\n",
    "#     patch_size = 16,\n",
    "#     d_model = 384,\n",
    "#     depth = 12,\n",
    "#     num_classes = 1000, \n",
    "#     expansion_factor = 4\n",
    "# )\n",
    "\n",
    "# model_jt = MLPMixer_jt(\n",
    "#     image_size=(224,112),\n",
    "#     patch_size=(16, 8),\n",
    "#     in_channels=3,\n",
    "#     num_classes=1000,\n",
    "#     d_model=256,\n",
    "#     depth=12,\n",
    "# )\n",
    "\n",
    "# model_jt = ViP_jt(\n",
    "#     image_size=(224, 112),\n",
    "#     patch_size=(16, 8),\n",
    "#     in_channels=3,\n",
    "#     num_classes=1000,\n",
    "#     d_model=256,\n",
    "#     depth=30,\n",
    "#     segments = 16,\n",
    "#     weighted = False\n",
    "# )\n",
    "\n",
    "model_jt = S2MLPv2_jt(\n",
    "    in_channels = 3,\n",
    "    image_size = (224,224),\n",
    "    patch_size = [7],\n",
    "    d_model = [384],\n",
    "    depth = [18],\n",
    "    num_classes = 1000, \n",
    "    expansion_factor = [3]\n",
    ")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "model_pt = gMLP_pt(\n",
    "    image_size=(224,224),\n",
    "    patch_size=16,\n",
    "    in_channels=3,\n",
    "    num_classes=1000,\n",
    "    d_model=256,\n",
    "    d_ffn=1536,\n",
    "    depth=30\n",
    ")\n",
    "\n",
    "# model_pt = ResMLP_pt(\n",
    "#     in_channels = 3,\n",
    "#     image_size = (224,112),\n",
    "#     patch_size = 16,\n",
    "#     d_model = 384,\n",
    "#     depth = 12,\n",
    "#     num_classes = 1000, \n",
    "#     expansion_factor = 4\n",
    "# )\n",
    "\n",
    "# model_pt = MLPMixer_pt(\n",
    "#     image_size=(224,112),\n",
    "#     patch_size=16,\n",
    "#     in_channels=3,\n",
    "#     num_classes=1000,\n",
    "#     d_model=256,\n",
    "#     depth=12,\n",
    "# )\n",
    "\n",
    "# model_pt = ViP_pt(\n",
    "#     image_size=(224, 112),\n",
    "#     patch_size=(16, 8),\n",
    "#     in_channels=3,\n",
    "#     num_classes=1000,\n",
    "#     d_model=256,\n",
    "#     depth=30,\n",
    "#     segments = 16,\n",
    "#     weighted = False\n",
    "# )\n",
    "\n",
    "# model_pt = S2MLPv2_pt(\n",
    "#     in_channels = 3,\n",
    "#     image_size = (224,224),\n",
    "#     patch_size = [(7,7), (2,2)],\n",
    "#     d_model = [192, 384],\n",
    "#     depth = [4, 14],\n",
    "#     num_classes = 1000, \n",
    "#     expansion_factor = [3, 3]\n",
    "# )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "images = jt.randn(8, 3, 224, 224)\n",
    "\n",
    "with jt.no_grad():\n",
    "    output = model_jt(images)\n",
    "print(output.shape)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "images = torch.randn(8, 3, 224, 224)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model_pt(images)\n",
    "print(output.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torchsummary import summary\n",
    "summary(model_pt, (3, 224, 224), device=\"cpu\")\n",
    "\n",
    "# from torchstat import stat\n",
    "# stat(model_pt, (3, 224, 224))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 时间性能测试方法"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "jt.flags.use_cuda = 1\n",
    "\n",
    "bs = 32\n",
    "test_img = np.random.random((bs,3,224,224)).astype('float32')\n",
    "\n",
    "# 定义 pytorch & jittor 输入矩阵\n",
    "pytorch_test_img = torch.Tensor(test_img).cuda()\n",
    "jittor_test_img = jt.array(test_img)\n",
    "\n",
    "# 跑turns次前向求平均值\n",
    "turns = 100\n",
    "\n",
    "# 定义 pytorch & jittor 的xxx模型，如vgg\n",
    "pytorch_model = MLPMixer_pt(\n",
    "                    image_size=(224,224),\n",
    "                    patch_size=16,\n",
    "                    in_channels=3,\n",
    "                    num_classes=1000,\n",
    "                    d_model=256,\n",
    "                    depth=12,\n",
    "                ).cuda()\n",
    "jittor_model = MLPMixer_jt(\n",
    "                    image_size=(224,224),\n",
    "                    patch_size=16,\n",
    "                    in_channels=3,\n",
    "                    num_classes=1000,\n",
    "                    d_model=256,\n",
    "                    depth=12,\n",
    "                )\n",
    "\n",
    "# 把模型都设置为eval来防止dropout层对输出结果的随机影响\n",
    "pytorch_model.eval()\n",
    "jittor_model.eval()\n",
    "\n",
    "# jittor加载pytorch的初始化参数来保证参数完全相同\n",
    "jittor_model.load_parameters(pytorch_model.state_dict())\n",
    "\n",
    "key = \"MLPMixer\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 测试Pytorch一次前向传播的平均用时\n",
    "for i in range(10):\n",
    "    pytorch_result = pytorch_model(pytorch_test_img) # Pytorch热身\n",
    "torch.cuda.synchronize()\n",
    "sta = time.time()\n",
    "for i in range(turns):\n",
    "    pytorch_result = pytorch_model(pytorch_test_img)\n",
    "torch.cuda.synchronize() # 只有运行了torch.cuda.synchronize()才会真正地运行，时间才是有效的，因此执行forward前后都要执行这句话\n",
    "end = time.time()\n",
    "tc_time = round((end - sta) / turns, 5) # 执行turns次的平均时间，输出时保留5位小数\n",
    "tc_fps = round(bs * turns / (end - sta),0) # 计算FPS\n",
    "print(f\"- Pytorch {key} forward average time cost: {tc_time}, Batch Size: {bs}, FPS: {tc_fps}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 测试Jittor一次前向传播的平均用时\n",
    "for i in range(10):\n",
    "    jittor_result = jittor_model(jittor_test_img) # Jittor热身\n",
    "    jittor_result.sync()\n",
    "jt.sync_all(True)\n",
    "# sync_all(true)是把计算图发射到计算设备上，并且同步。只有运行了jt.sync_all(True)才会真正地运行，时间才是有效的，因此执行forward前后都要执行这句话\n",
    "sta = time.time()\n",
    "for i in range(turns):\n",
    "    jittor_result = jittor_model(jittor_test_img)\n",
    "    jittor_result.sync() # sync是把计算图发送到计算设备上\n",
    "jt.sync_all(True)\n",
    "end = time.time()\n",
    "jt_time = round((time.time() - sta) / turns, 5) # 执行turns次的平均时间，输出时保留5位小数\n",
    "jt_fps = round(bs * turns / (end - sta),0) # 计算FPS\n",
    "print(f\"- Jittor {key} forward average time cost: {jt_time}, Batch Size: {bs}, FPS: {jt_fps}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "threshold = 1e-3\n",
    "# 计算 pytorch & jittor 前向结果相对误差. 如果误差小于threshold，则测试通过.\n",
    "x = pytorch_result.detach().cpu().numpy() + 1\n",
    "y = jittor_result.data + 1\n",
    "relative_error = abs(x - y) / abs(y)\n",
    "diff = relative_error.mean()\n",
    "assert diff < threshold, f\"[*] {key} forward fails..., Relative Error: {diff}\"\n",
    "print(f\"[*] {key} forword passes with Relative Error {diff}\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "33c023bf5980af423125aca9a625c46b0823ed829175682be9d8faf5aeee714b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}